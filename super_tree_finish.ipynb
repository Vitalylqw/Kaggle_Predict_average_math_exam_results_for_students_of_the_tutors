{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим полные рабочие данные в нумпай\n",
    "X = pd.read_csv('x_train.csv')\n",
    "X_train=X.to_numpy()\n",
    "X_test = pd.read_csv('x_test.csv')\n",
    "y = pd.read_csv('y_train.csv')\n",
    "y_train = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTreeFastMse():\n",
    "\n",
    "    # объявляем характеристики класса\n",
    "    def __init__(self, max_depth=5, min_size=5):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.value = 0\n",
    "        self.feature_idx = -1\n",
    "        self.feature_threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    # процедура обучения - сюда передается обучающая выборка\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # начальное значение - среднее значение y\n",
    "        self.value = y.mean()\n",
    "        # начальная ошибка - mse между значением в листе (пока нет\n",
    "        # разбиения, это среднее по всем объектам) и объектами\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # пришли в максимальную глубину\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        left_value, right_value = 0, 0\n",
    "        \n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            prev_error1, prev_error2 = base_error, 0 \n",
    "            idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # переменные для быстрого переброса суммы\n",
    "            mean1, mean2 = y.mean(), 0\n",
    "            sm1, sm2 = y.sum(), 0\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "\n",
    "                idx = idxs[thres]\n",
    "                x = X[idx, feat]\n",
    "                \n",
    "                # вычисляем дельты - по ним в основном будет делаться переброс\n",
    "                delta1 = (sm1 - y[idx]) * 1.0 / N1 - mean1\n",
    "                delta2 = (sm2 + y[idx]) * 1.0 / N2 - mean2\n",
    "                \n",
    "                # увеличиваем суммы\n",
    "                sm1 -= y[idx]\n",
    "                sm2 += y[idx]\n",
    "                \n",
    "                # пересчитываем ошибки за O(1)\n",
    "                prev_error1 += (delta1**2) * N1 \n",
    "                prev_error1 -= (y[idx] - mean1)**2 \n",
    "                prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1)\n",
    "                mean1 = sm1/N1\n",
    "                \n",
    "                prev_error2 += (delta2**2) * N2 \n",
    "                prev_error2 += (y[idx] - mean2)**2 \n",
    "                prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2)\n",
    "                mean2 = sm2/N2\n",
    "                \n",
    "                # пропускаем близкие друг к другу значения\n",
    "                if thres < N - 1 and np.abs(x - X[idxs[thres + 1], feat]) < 1e-5:\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # 2 условия, чтобы осуществить сплит - уменьшение ошибки \n",
    "                # и минимальное кол-о эл-в в каждом листе\n",
    "                if (prev_error1 + prev_error2 < error):\n",
    "                    if (min(N1,N2) > self.min_size):\n",
    "                    \n",
    "                        # переопределяем самый лучший признак и границу по нему\n",
    "                        self.feature_idx, self.feature_threshold = feat, x\n",
    "                        # переопределяем значения в листах\n",
    "                        left_value, right_value = mean1, mean2\n",
    "\n",
    "                        # флаг - значит сделали хороший сплит\n",
    "                        flag = 1\n",
    "                        error = prev_error1 + prev_error2\n",
    "                                     \n",
    "                thres += 1\n",
    " \n",
    "        # ничего не разделили, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        self.left = RegressionTreeFastMse(self.max_depth - 1)\n",
    "      \n",
    "        self.left.value = left_value\n",
    "        self.right = RegressionTreeFastMse(self.max_depth - 1)\n",
    "       \n",
    "        self.right.value = right_value\n",
    "        \n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "    \n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])    \n",
    "        return y\n",
    "    \n",
    "    def R2(self,y_pred,y):\n",
    "        return 1- ((y_pred - y)**2).sum()/((y-y.mean())**2).sum()\n",
    "    \n",
    "    def cross_validation(self,n,size):\n",
    "        data=[]\n",
    "        r = np.arange(n)\n",
    "        for i in range(size-1):\n",
    "            ind = np.random.choice(r,size=int(n/size), replace=False)\n",
    "            data.append(ind)\n",
    "            r=np.setdiff1d(r,ind) \n",
    "        data.append(r)\n",
    "        return data\n",
    "    \n",
    "    def test_cros(self,X,y,size=5,print_res =True):\n",
    "        cros_val = self.cross_validation(X.shape[0],size)\n",
    "        data=[]\n",
    "        for i in range(len(cros_val)):\n",
    "            ind_train = np.hstack((cros_val[:i]+cros_val[i+1:]))\n",
    "            ind_test = cros_val[i]\n",
    "            self.fit(X[ind_train],y[ind_train])\n",
    "            pred_train = self.predict(X[ind_train])\n",
    "            pred_test =  self.predict(X[ind_test])\n",
    "            r2_test = self.R2(pred_test,y[ind_test])\n",
    "            r2_train = self.R2(pred_train,y[ind_train])\n",
    "            data.append((r2_test,r2_train))\n",
    "            if print_res:\n",
    "                print(f'Выборка номер {i} r2 на обучении {r2_train}, r2 на тесте {r2_test}')\n",
    "                \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На дереве , на крос валидации самые лучшие результаты пока зали параметры max_depth=8, min_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=RegressionTreeFastMse(max_depth=8, min_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка номер 0 r2 на обучении 0.7915959164466697, r2 на тесте 0.7717467556656621\n",
      "Выборка номер 1 r2 на обучении 0.7917916269070135, r2 на тесте 0.7698251000609865\n",
      "Выборка номер 2 r2 на обучении 0.792531621202675, r2 на тесте 0.765417251665544\n",
      "Выборка номер 3 r2 на обучении 0.7887532028177741, r2 на тесте 0.780647948136619\n",
      "Выборка номер 4 r2 на обучении 0.7895449829120512, r2 на тесте 0.7833661570832422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7717467556656621, 0.7915959164466697),\n",
       " (0.7698251000609865, 0.7917916269070135),\n",
       " (0.765417251665544, 0.792531621202675),\n",
       " (0.780647948136619, 0.7887532028177741),\n",
       " (0.7833661570832422, 0.7895449829120512)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.test_cros(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно дерево показывает уже прекрасные результаты, близкие к предельным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
