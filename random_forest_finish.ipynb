{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 'train.csv'\n",
    "TEST = 'test.csv'\n",
    "df_correct_file = 'df_correct.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN)\n",
    "df_correct = pd.read_csv(df_correct_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим полные рабочие данные в нумпай\n",
    "X = pd.read_csv('x_train.csv')\n",
    "X_train=X.to_numpy()\n",
    "X_test = pd.read_csv('x_test.csv')\n",
    "y = pd.read_csv('y_train.csv')\n",
    "y_train = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTreeFastMse():\n",
    "    \n",
    "    # объявляем характеристики класса\n",
    "    def __init__(self, max_depth=5, min_size=5):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.value = 0\n",
    "        self.feature_idx = -1\n",
    "        self.feature_threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    # процедура обучения - сюда передается обучающая выборка\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # начальное значение - среднее значение y\n",
    "        self.value = y.mean()\n",
    "        # начальная ошибка - mse между значением в листе (пока нет\n",
    "        # разбиения, это среднее по всем объектам) и объектами\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # пришли в максимальную глубину\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        left_value, right_value = 0, 0\n",
    "        \n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            prev_error1, prev_error2 = base_error, 0 \n",
    "            idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # переменные для быстрого переброса суммы\n",
    "            mean1, mean2 = y.mean(), 0\n",
    "            sm1, sm2 = y.sum(), 0\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "\n",
    "                idx = idxs[thres]\n",
    "                x = X[idx, feat]\n",
    "                \n",
    "                # вычисляем дельты - по ним в основном будет делаться переброс\n",
    "                delta1 = (sm1 - y[idx]) * 1.0 / N1 - mean1\n",
    "                delta2 = (sm2 + y[idx]) * 1.0 / N2 - mean2\n",
    "                \n",
    "                # увеличиваем суммы\n",
    "                sm1 -= y[idx]\n",
    "                sm2 += y[idx]\n",
    "                \n",
    "                # пересчитываем ошибки за O(1)\n",
    "                prev_error1 += (delta1**2) * N1 \n",
    "                prev_error1 -= (y[idx] - mean1)**2 \n",
    "                prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1)\n",
    "                mean1 = sm1/N1\n",
    "                \n",
    "                prev_error2 += (delta2**2) * N2 \n",
    "                prev_error2 += (y[idx] - mean2)**2 \n",
    "                prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2)\n",
    "                mean2 = sm2/N2\n",
    "                \n",
    "                # пропускаем близкие друг к другу значения\n",
    "                if thres < N - 1 and np.abs(x - X[idxs[thres + 1], feat]) < 1e-5:\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # 2 условия, чтобы осуществить сплит - уменьшение ошибки \n",
    "                # и минимальное кол-о эл-в в каждом листе\n",
    "                if (prev_error1 + prev_error2 < error):\n",
    "                    if (min(N1,N2) > self.min_size):\n",
    "                    \n",
    "                        # переопределяем самый лучший признак и границу по нему\n",
    "                        self.feature_idx, self.feature_threshold = feat, x\n",
    "                        # переопределяем значения в листах\n",
    "                        left_value, right_value = mean1, mean2\n",
    "\n",
    "                        # флаг - значит сделали хороший сплит\n",
    "                        flag = 1\n",
    "                        error = prev_error1 + prev_error2\n",
    "                                     \n",
    "                thres += 1\n",
    " \n",
    "        # ничего не разделили, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        self.left = RegressionTreeFastMse(self.max_depth - 1)\n",
    "        # print (\"Левое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.left.value = left_value\n",
    "        self.right = RegressionTreeFastMse(self.max_depth - 1)\n",
    "        # print (\"Правое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.right.value = right_value\n",
    "        \n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "    \n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])    \n",
    "        return y\n",
    "    \n",
    "    def R2(self,y_pred,y):\n",
    "        return 1- ((y_pred - y)**2).sum()/((y-y.mean())**2).sum()\n",
    "    \n",
    "    def cross_validation(self,n,size):\n",
    "        data=[]\n",
    "        r = np.arange(n)\n",
    "        for i in range(size-1):\n",
    "            ind = np.random.choice(r,size=int(n/size), replace=False)\n",
    "            data.append(ind)\n",
    "            r=np.setdiff1d(r,ind) \n",
    "        data.append(r)\n",
    "        return data\n",
    "    \n",
    "    def test_cros(self,X,y,size=5,print_res =True):\n",
    "        cros_val = self.cross_validation(X.shape[0],size)\n",
    "        data=[]\n",
    "        for i in range(len(cros_val)):\n",
    "            ind_train = np.hstack((cros_val[:i]+cros_val[i+1:]))\n",
    "            ind_test = cros_val[i]\n",
    "            self.fit(X[ind_train],y[ind_train])\n",
    "            pred_train = self.predict(X[ind_train])\n",
    "            pred_test =  self.predict(X[ind_test])\n",
    "            r2_test = self.R2(pred_test,y[ind_test])\n",
    "            r2_train = self.R2(pred_train,y[ind_train])\n",
    "            data.append((r2_test,r2_train))\n",
    "            if print_res:\n",
    "                print(f'Выборка номер {i} r2 на обучении {r2_train}, r2 на тесте {r2_test}')              \n",
    "        return data\n",
    " \n",
    "\n",
    "\n",
    "# 88888\n",
    "def get_bootstrap(data, labels, N):\n",
    "        n_samples = data.shape[0]\n",
    "        bootstrap = []\n",
    "        out_index=[]\n",
    "        for i in range(N):\n",
    "            sample_index = np.random.randint(0,n_samples,n_samples-1)\n",
    "            bootstrap.append((data[sample_index],labels[sample_index],)) \n",
    "        return bootstrap  \n",
    "\n",
    "    \n",
    "def random_forest(data, labels, n_trees=50,max_depth=6, min_size=5):\n",
    "        forest = []\n",
    "        bootstrap = get_bootstrap(data, labels, n_trees)\n",
    "        for b_data, b_labels in bootstrap:\n",
    "            tree= RegressionTreeFastMse(max_depth=max_depth, min_size=min_size)\n",
    "            tree.fit(b_data,b_labels)\n",
    "            forest.append(tree)\n",
    "        return forest\n",
    "\n",
    "def predict(forest,data):\n",
    "    # добавим предсказания всех деревьев в список\n",
    "    predictions = []\n",
    "    for tree in forest:\n",
    "        predictions.append(tree.predict(data))\n",
    "    # сформируем список с предсказаниями для каждого объекта\n",
    "    predictions_per_object = list(zip(*predictions))\n",
    "   \n",
    "        # выберем в качестве итогового предсказания для каждого объекта то,\n",
    "        # за которое проголосовало большинство деревьев\n",
    "    voted_predictions = []\n",
    "    for obj in predictions_per_object:\n",
    "        c = np.array(obj)\n",
    "        voted_predictions.append(c.mean())\n",
    "    return voted_predictions  \n",
    "    \n",
    "def R2(y_pred,y):\n",
    "        return 1- ((y_pred - y)**2).sum()/((y-y.mean())**2).sum()\n",
    "    \n",
    "    \n",
    "def cross_validation(n,size):\n",
    "        data=[]\n",
    "        r = np.arange(n)\n",
    "        for i in range(size-1):\n",
    "            ind = np.random.choice(r,size=int(n/size), replace=False)\n",
    "            data.append(ind)\n",
    "            r=np.setdiff1d(r,ind) \n",
    "        data.append(r)\n",
    "        return data\n",
    "    \n",
    "def test_cros(X,y,size=5,print_res =True,n_trees=50,max_depth=6, min_size=5):\n",
    "        cros_val = cross_validation(X.shape[0],size)\n",
    "        data=[]\n",
    "        for i in range(len(cros_val)):\n",
    "            ind_train = np.hstack((cros_val[:i]+cros_val[i+1:]))\n",
    "            ind_test = cros_val[i]\n",
    "            forest = random_forest(X[ind_train],y[ind_train],n_trees=n_trees,max_depth=max_depth, min_size=min_size)\n",
    "            pred_train = predict(forest,X[ind_train])\n",
    "            pred_test =  predict(forest,X[ind_test])\n",
    "            r2_test = R2(pred_test,y[ind_test])\n",
    "            r2_train = R2(pred_train,y[ind_train])\n",
    "            data.append((r2_test,r2_train))\n",
    "            if print_res:\n",
    "                print(f'Выборка номер {i} r2 на обучении {r2_train}, r2 на тесте {r2_test}')              \n",
    "        return data    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборка номер 0 r2 на обучении 0.7948372848636587, r2 на тесте 0.7869539439993711\n",
      "Выборка номер 1 r2 на обучении 0.7970695955158379, r2 на тесте 0.7802976404752993\n",
      "Выборка номер 2 r2 на обучении 0.7956236338972333, r2 на тесте 0.7828409054260899\n",
      "Выборка номер 3 r2 на обучении 0.7940176227127876, r2 на тесте 0.7901265101460573\n",
      "Выборка номер 4 r2 на обучении 0.8003073219298611, r2 на тесте 0.7640365183312046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7869539439993711, 0.7948372848636587),\n",
       " (0.7802976404752993, 0.7970695955158379),\n",
       " (0.7828409054260899, 0.7956236338972333),\n",
       " (0.7901265101460573, 0.7940176227127876),\n",
       " (0.7640365183312046, 0.8003073219298611)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cros(X_train,np.ravel(y_train),n_trees=100,max_depth=8, min_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
