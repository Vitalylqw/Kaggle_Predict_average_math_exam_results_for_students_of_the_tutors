Ваша задача этом соревновании - предсказать средний балл на экзамене по математике, 
который получают ученики репетиторов из датасета test.csv. 
Вам будут даны два датасета: train.csv (содержит признаки и целевую переменную) и test.csv (только признаки).

Метрика для оценки – Коэффициент детерминации:

R2=1−σ2/σ2y

1. Данные. см ноутбук 'analys_data'
Данные представленые слудующими полямиЖ
['Id',
 'age',
 'years_of_experience',
 'lesson_price',
 'qualification',
 'physics',
 'chemistry',
 'biology',
 'english',
 'geography',
 'history',
 'mean_exam_points']

где ID сразу поле для удаления
mean_exam_points - таргет
Остальные все понятны.
Данные "хорошие" отсутвуют пропуски, нет ошибок и выбросов.
Тапргет имеет распределение близко к норманльному, без выбросов средняя возле медианы.

Наиболее сильное влияние на целевую переменную имеют :
1. lesson_price
2. years_of_experience
3. qualification

Практически не влияют на таргет:
1. age
2. history
3. geography
4. english


Генерация новых фич

1. Создадим столбец в котром будет указана сумму предметов, по которым работает репетитор (сумма предметных столбцов)
2. Создадим два столбца , которые оценивают категорию уенообразования от 1 до 4 и соответсвенно опыт лет 1-4.
от 1 до 4, потому что qualification имеет то же 4 градации. Что бы можно было построить рейтинг. (см. файл)
3. Создадим столбец рейтин путем сумирования трех уровней (стоиомсти, опыта и професиоонализма), каждый  показатель будем умножать на вес.
 Вес это коэф. Кендала, который показывает вляиние на фактор.
4. Созадим столбец 'норма' взяв за основу евклилдову норму трех самых важных показателей

После огромного количесвта испытаний на разных моделях, 
параметрах и гиперпараметров, выяснилось, что самsй лучий результат дают данные в слкдующей комбинации:
[ 'years_of_experience',
 'lesson_price',
 'qualification',
 'physics',
 'chemistry',
 'biology',
 'english',
]

Далее я попытался отчеь выбросы на участак целевой переменной. То есть рассматривать участок например от 60 до 65 и смотреть есть ли там выбросы и удалть их.
Но это то же результата не дало.

В итоге самые лучшие результаты давал надор данных выше.


1. Линейная модель (файл Line_reg)
Линейная модель на крос валиалции смогла показать максимальный результат 0,65 - что не удовлетворительно

2. Очень хорошие результаты показало дерефо рений (super_tree)
Это результаты близуие к предельныйм в районе 0,78. Лучшие параметры для дерева max_depth=8, min_size=5

3. Случайный лес. Показал результаты немного лучше. Именно на нем удалось добиться максимального результата на кагле
Лушичшие параметры были обнаруженыт следующие: random forest n_trees=100,max_depth=8, min_size=5
Причем на крос валидации параметр качества достигал в среднем 0,783, но Leaderboard показал максимум 0.78208 - 16 место. Более его увелисить не удавалось

4. Градиентный бустинг. На крос валидации , на отложенных выборках показывал результаты лучше леса, но  на Leaderboard  не смог подняться выше результата леса.
На крос валидации резудьтаты доходили (на отложенной выборке) до 0,7831 причем стабильных, но Leaderboard  говорил  - нет!

5. Для интереса опоробовал метод ближайших соседей. Очень интересно. Дало не плохие результаты, конечно далеко не лучшие.
здсь лучше отработал вариант с весами зависящими от растояния. результат где то 0.7










